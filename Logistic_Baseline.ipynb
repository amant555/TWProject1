{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os, gc, seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_transaction.csv',\n",
       " 'train_identity.csv',\n",
       " 'test_identity.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_transaction.csv']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_identity = pd.read_csv(\"../data/train_identity.csv\")\n",
    "train_transaction = pd.read_csv(\"../data/train_transaction.csv\")\n",
    "test_transaction = pd.read_csv(\"../data/test_transaction.csv\")\n",
    "test_identity = pd.read_csv(\"../data/test_identity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions of the Train Identity set:',train_identity.shape)\n",
    "print('Dimensions of the Train transaction set:',train_transaction.shape)\n",
    "print('Dimensions of the Test transaction set:',test_transaction.shape)\n",
    "print('Dimensions of the Test Identity set:',test_identity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge both the transaction and identity by left\n",
    "train_data=pd.merge(train_transaction,train_identity,how=\"left\",on=\"TransactionID\")\n",
    "test_data=pd.merge(test_transaction,test_identity,how=\"left\",on=\"TransactionID\")\n",
    "dicti={}\n",
    "for i in range(1,10):\n",
    "    dicti.update({'id-0'+str(i):'id_0'+str(i)})\n",
    "for i in range(10,39):\n",
    "    dicti.update({'id-'+str(i):'id_'+str(i)})\n",
    "test_data=test_data.rename(columns=dicti)\n",
    "del dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Shapes\n",
    "print(\"Train Dataset shape: \", train_data.shape)\n",
    "print(\"Test Dataset shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_identity\n",
    "del train_transaction\n",
    "del test_transaction\n",
    "del test_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Explore Categorical features\n",
    "print('Training set:')\n",
    "l1=[];l2=[];\n",
    "for _ in train_data.columns:\n",
    "    if train_data[_].dtypes == 'object' :\n",
    "        value = len(train_data[_].unique())\n",
    "        l1.append(_)\n",
    "        l2.append(value)\n",
    "frame=pd.DataFrame(np.column_stack((np.array(l1),np.array(l2))),columns=['Column_Name','Category_Count'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "print('Test set:')\n",
    "l1=[];l2=[];\n",
    "for _ in test_data.columns:\n",
    "    if test_data[_].dtypes == 'object' :\n",
    "        value = len(test_data[_].unique())\n",
    "        l1.append(_)\n",
    "        l2.append(value)\n",
    "frame=pd.DataFrame(np.column_stack((np.array(l1),np.array(l2))),columns=['Column_Name','Category_Count'])\n",
    "del l1,l2\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_fraud = len(train_data[train_data['isFraud']==1].index)*100/train_data.shape[0]\n",
    "print(\"Percentage of Fradaulent records in dataset {:.2f}\".format(perc_fraud) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data - Many Columns have more than 50% NA/Null records\n",
    "def missing_data(df) :\n",
    "    count = df.isnull().sum()\n",
    "    percent = (df.isnull().sum()) / (df.isnull().count()) * 100\n",
    "    total = pd.concat([count, percent], axis=1, keys = ['Count', 'Percent'])\n",
    "    types = []\n",
    "    for col in df.columns :\n",
    "        dtypes = str(df[col].dtype)\n",
    "        types.append(dtypes)\n",
    "    total['dtypes'] = types\n",
    "    \n",
    "    return np.transpose(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I have dropped columns who has NULL values more than given percentage\n",
    "null_percent = train_data.isnull().sum()/train_data.shape[0]*100\n",
    "\n",
    "cols_to_drop = np.array(null_percent[null_percent > percentage].index)\n",
    "\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Columns\n",
    "train_data = train_data.drop(cols_to_drop, axis=1)\n",
    "test_data = test_data.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill NaNs\n",
    "\n",
    "train_data = train_data.fillna(train_data._get_numeric_data().mean())\n",
    "test_data = test_data.fillna(test_data._get_numeric_data().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(1)\n",
    "test_data = test_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['isFraud']\n",
    "train_X = train_data.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for categorical variables.\n",
    "for _ in train_X.columns:\n",
    "    if train_X[_].dtype=='object' or test_data[_].dtype=='object': \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(train_X[_].values) + list(test_data[_].values))\n",
    "        train_X[_] = le.transform(list(train_X[_].values))\n",
    "        test_data[_] = le.transform(list(test_data[_].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change cell from markdown to code Run only if memory issue arises \n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init(memory=10737418240, object_store_memory=10737418240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3663549</th>\n",
       "      <td>0.042166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663550</th>\n",
       "      <td>0.042167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663551</th>\n",
       "      <td>0.042168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663552</th>\n",
       "      <td>0.042166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663553</th>\n",
       "      <td>0.042165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                isFraud\n",
       "TransactionID          \n",
       "3663549        0.042166\n",
       "3663550        0.042167\n",
       "3663551        0.042168\n",
       "3663552        0.042166\n",
       "3663553        0.042165"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv',index_col='TransactionID')\n",
    "submission['isFraud'] = logreg.predict_proba(test_data)[:,1]\n",
    "submission.to_csv('Logreg_submissionp.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
